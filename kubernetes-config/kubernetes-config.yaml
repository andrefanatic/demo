apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T18:10:23Z"
    generateName: coredns-77ccd57875-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 77ccd57875
    name: coredns-77ccd57875-9cqmf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-77ccd57875
      uid: 6005681a-ec0c-4eef-9581-cc177eb0dc06
    resourceVersion: "484"
    uid: 28de2ed7-6069-4c68-aa18-eea65074550a
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: rancher/mirrored-coredns-coredns:1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6k2sh
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          k8s-app: kube-dns
      maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        - key: NodeHosts
          path: NodeHosts
        name: coredns
      name: config-volume
    - configMap:
        defaultMode: 420
        name: coredns-custom
        optional: true
      name: custom-config-volume
    - name: kube-api-access-6k2sh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9c1c91b6f3386cb20033cf2fd20bec5a47d6cd5f80225fdf1f8dbda973716488
      image: docker.io/rancher/mirrored-coredns-coredns:1.10.1
      imageID: docker.io/rancher/mirrored-coredns-coredns@sha256:a11fafae1f8037cbbd66c5afa40ba2423936b72b4fd50a7034a7e8b955163594
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:10:48Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.4
    podIPs:
    - ip: 10.42.0.4
    qosClass: Burstable
    startTime: "2024-03-14T18:10:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T18:10:23Z"
    generateName: local-path-provisioner-957fdf8bc-
    labels:
      app: local-path-provisioner
      pod-template-hash: 957fdf8bc
    name: local-path-provisioner-957fdf8bc-xl7tm
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: local-path-provisioner-957fdf8bc
      uid: 316f82c2-47a5-4b8b-b49e-2ff80d439ba6
    resourceVersion: "488"
    uid: 5d53bd42-5022-4093-b2e9-74d4fced6cf9
  spec:
    containers:
    - command:
      - local-path-provisioner
      - start
      - --config
      - /etc/config/config.json
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/local-path-provisioner:v0.0.24
      imagePullPolicy: IfNotPresent
      name: local-path-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2hrqk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: local-path-provisioner-service-account
    serviceAccountName: local-path-provisioner-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: local-path-config
      name: config-volume
    - name: kube-api-access-2hrqk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://be947535c8418341984b9524f228ede0c9b382858636ccf40ab48f099d3bd93a
      image: docker.io/rancher/local-path-provisioner:v0.0.24
      imageID: docker.io/rancher/local-path-provisioner@sha256:5bb33992a4ec3034c28b5e0b3c4c2ac35d3613b25b79455eb4b1a95adc82cdc0
      lastState: {}
      name: local-path-provisioner
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:10:48Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.5
    podIPs:
    - ip: 10.42.0.5
    qosClass: BestEffort
    startTime: "2024-03-14T18:10:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T18:10:23Z"
    generateName: metrics-server-648b5df564-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 648b5df564
    name: metrics-server-648b5df564-58rg4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-648b5df564
      uid: fed973cf-7d15-480e-9c16-86c686e3b73b
    resourceVersion: "542"
    uid: 6f631f64-09f0-44c7-89ce-d6ff156db453
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=10250
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
      image: rancher/mirrored-metrics-server:v0.6.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4rd7q
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-4rd7q
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:01Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:01Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b72cc26eb77ce41af03b7e947bde920f86f6f8face98479c17638c8bc956430c
      image: docker.io/rancher/mirrored-metrics-server:v0.6.3
      imageID: docker.io/rancher/mirrored-metrics-server@sha256:c2dfd72bafd6406ed306d9fbd07f55c496b004293d13d3de88a4567eacc36558
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:10:45Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.2
    podIPs:
    - ip: 10.42.0.2
    qosClass: Burstable
    startTime: "2024-03-14T18:10:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
    creationTimestamp: "2024-03-14T18:10:23Z"
    generateName: helm-install-traefik-crd-
    labels:
      batch.kubernetes.io/controller-uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
      batch.kubernetes.io/job-name: helm-install-traefik-crd
      controller-uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
      helmcharts.helm.cattle.io/chart: traefik-crd
      job-name: helm-install-traefik-crd
    name: helm-install-traefik-crd-kwrqf
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik-crd
      uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
    resourceVersion: "599"
    uid: aa30e456-a6bd-4509-b5da-9f3782324ab4
  spec:
    containers:
    - args:
      - install
      env:
      - name: NAME
        value: traefik-crd
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-crd-21.2.1+up21.2.0.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.0-build20230510
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-sxxml
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: helm-traefik-crd
    serviceAccountName: helm-traefik-crd
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik-crd
    - configMap:
        defaultMode: 420
        name: chart-content-traefik-crd
      name: content
    - name: kube-api-access-sxxml
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:24Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:04Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:04Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://41d19427f5ff1e14184a25b0eaced2f9bca3fbb754c30d55f941a65eee50fe87
      image: docker.io/rancher/klipper-helm:v0.8.0-build20230510
      imageID: docker.io/rancher/klipper-helm@sha256:4d2ec9ac78f6e3ca3d4dd0a1c3b754aec2b4f19e3a922c6ebcb0d74bb5ac674a
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://41d19427f5ff1e14184a25b0eaced2f9bca3fbb754c30d55f941a65eee50fe87
          exitCode: 0
          finishedAt: "2024-03-14T18:11:00Z"
          message: |
            Installing helm_v3 chart
          reason: Completed
          startedAt: "2024-03-14T18:10:57Z"
    hostIP: 172.18.0.3
    phase: Succeeded
    podIP: 10.42.0.6
    podIPs:
    - ip: 10.42.0.6
    qosClass: BestEffort
    startTime: "2024-03-14T18:10:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=57C38B9FBB6B3E3C05F8793EC0355D9955F740BA54D7EF2D96D97F8D678F2B0E
    creationTimestamp: "2024-03-14T18:10:23Z"
    generateName: helm-install-traefik-
    labels:
      batch.kubernetes.io/controller-uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
      batch.kubernetes.io/job-name: helm-install-traefik
      controller-uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
      helmcharts.helm.cattle.io/chart: traefik
      job-name: helm-install-traefik
    name: helm-install-traefik-8k7bq
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik
      uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
    resourceVersion: "609"
    uid: 2ddb9561-5839-4fb1-a164-917264bb4eb0
  spec:
    containers:
    - args:
      - install
      - --set-string
      - global.systemDefaultRegistry=
      env:
      - name: NAME
        value: traefik
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-21.2.1+up21.2.0.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.0-build20230510
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9vjsr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: helm-traefik
    serviceAccountName: helm-traefik
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik
    - configMap:
        defaultMode: 420
        name: chart-content-traefik
      name: content
    - name: kube-api-access-9vjsr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:24Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:06Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:06Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:10:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://29e2afbe38444b82721b8057814ceaf64ca59ad89bca528e4542c85f9fa6a12c
      image: docker.io/rancher/klipper-helm:v0.8.0-build20230510
      imageID: docker.io/rancher/klipper-helm@sha256:4d2ec9ac78f6e3ca3d4dd0a1c3b754aec2b4f19e3a922c6ebcb0d74bb5ac674a
      lastState: {}
      name: helm
      ready: false
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://29e2afbe38444b82721b8057814ceaf64ca59ad89bca528e4542c85f9fa6a12c
          exitCode: 0
          finishedAt: "2024-03-14T18:11:05Z"
          message: |
            Installing helm_v3 chart
          reason: Completed
          startedAt: "2024-03-14T18:11:05Z"
    hostIP: 172.18.0.3
    phase: Succeeded
    podIP: 10.42.0.3
    podIPs:
    - ip: 10.42.0.3
    qosClass: BestEffort
    startTime: "2024-03-14T18:10:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T18:11:05Z"
    generateName: svclb-traefik-11809822-
    labels:
      app: svclb-traefik-11809822
      controller-revision-hash: 7645dd8b4
      pod-template-generation: "1"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-11809822-qhm8x
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: svclb-traefik-11809822
      uid: 10256f8f-936e-44c1-84e7-4322f354ef90
    resourceVersion: "620"
    uid: 326143be-7df7-4eb9-9166-bb0a876b981a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k3d-demo-server-0
    automountServiceAccountToken: false
    containers:
    - env:
      - name: SRC_PORT
        value: "80"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "80"
      - name: DEST_IPS
        value: 10.43.146.215
      image: rancher/klipper-lb:v0.4.4
      imagePullPolicy: IfNotPresent
      name: lb-tcp-80
      ports:
      - containerPort: 80
        hostPort: 80
        name: lb-tcp-80
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    - env:
      - name: SRC_PORT
        value: "443"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "443"
      - name: DEST_IPS
        value: 10.43.146.215
      image: rancher/klipper-lb:v0.4.4
      imagePullPolicy: IfNotPresent
      name: lb-tcp-443
      ports:
      - containerPort: 443
        hostPort: 443
        name: lb-tcp-443
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      sysctls:
      - name: net.ipv4.ip_forward
        value: "1"
    serviceAccount: svclb
    serviceAccountName: svclb
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:05Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:05Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://aa28ae668280b19e187caabc4a3c8adacfe7f25912fbe9c337c7021bf009d95a
      image: docker.io/rancher/klipper-lb:v0.4.4
      imageID: docker.io/rancher/klipper-lb@sha256:d6780e97ac25454b56f88410b236d52572518040f11d0db5c6baaac0d2fcf860
      lastState: {}
      name: lb-tcp-443
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:11:17Z"
    - containerID: containerd://0ba5c2bee67a5a82306e041b2e3894db0faefdeff33927c774c8c06b2dd0ac9c
      image: docker.io/rancher/klipper-lb:v0.4.4
      imageID: docker.io/rancher/klipper-lb@sha256:d6780e97ac25454b56f88410b236d52572518040f11d0db5c6baaac0d2fcf860
      lastState: {}
      name: lb-tcp-80
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:11:17Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.7
    podIPs:
    - ip: 10.42.0.7
    qosClass: BestEffort
    startTime: "2024-03-14T18:11:05Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9100"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-03-14T18:11:05Z"
    generateName: traefik-64f55bb67d-
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-21.2.1_up21.2.0
      pod-template-hash: 64f55bb67d
    name: traefik-64f55bb67d-j2f6n
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: traefik-64f55bb67d
      uid: 3df2d24f-7ad6-4e00-9ac6-4f21e217cb57
    resourceVersion: "633"
    uid: 13de5073-3a94-4803-bb4a-cefaa95f0b92
  spec:
    containers:
    - args:
      - --global.checknewversion
      - --global.sendanonymoususage
      - --entrypoints.metrics.address=:9100/tcp
      - --entrypoints.traefik.address=:9000/tcp
      - --entrypoints.web.address=:8000/tcp
      - --entrypoints.websecure.address=:8443/tcp
      - --api.dashboard=true
      - --ping=true
      - --metrics.prometheus=true
      - --metrics.prometheus.entrypoint=metrics
      - --providers.kubernetescrd
      - --providers.kubernetesingress
      - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
      - --entrypoints.websecure.http.tls=true
      image: rancher/mirrored-library-traefik:2.9.10
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      name: traefik
      ports:
      - containerPort: 9100
        name: metrics
        protocol: TCP
      - containerPort: 9000
        name: traefik
        protocol: TCP
      - containerPort: 8000
        name: web
        protocol: TCP
      - containerPort: 8443
        name: websecure
        protocol: TCP
      readinessProbe:
        failureThreshold: 1
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      resources: {}
      securityContext:
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data
        name: data
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9ckl5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65532
    serviceAccount: traefik
    serviceAccountName: traefik
    terminationGracePeriodSeconds: 60
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: data
    - emptyDir: {}
      name: tmp
    - name: kube-api-access-9ckl5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:05Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:11:05Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dfefa063997a7b3403d37709a39fb3ee19657f7bcc140a7e56956894ee62a971
      image: docker.io/rancher/mirrored-library-traefik:2.9.10
      imageID: docker.io/rancher/mirrored-library-traefik@sha256:aaec134463b277ca7aa4f88807c8b67f2ec05d92a8f0432c0540b7ecc8fe724a
      lastState: {}
      name: traefik
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:11:18Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.8
    podIPs:
    - ip: 10.42.0.8
    qosClass: BestEffort
    startTime: "2024-03-14T18:11:05Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T18:25:37Z"
    generateName: demo-794b7cb558-
    labels:
      app: demo
      pod-template-hash: 794b7cb558
    name: demo-794b7cb558-6f497
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: demo-794b7cb558
      uid: 649259dd-b46d-43b8-8e66-9dcb31b2ffd8
    resourceVersion: "920"
    uid: 7d07f26b-8c50-4b96-a676-4f5cd8a7ae0f
  spec:
    containers:
    - image: andriy1fanatic/app:v1.0.0
      imagePullPolicy: IfNotPresent
      name: app
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-68d47
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-68d47
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:25:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:26:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:26:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:25:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1a34bf27a75c16e6659dd3a189a764682ba1890c45fd050f4532bed367048965
      image: docker.io/andriy1fanatic/app:v1.0.0
      imageID: docker.io/andriy1fanatic/app@sha256:86e6e5c85c309dda718d4942fea38e1595e6ef23c9f933a2d0b025c505d2dbe1
      lastState: {}
      name: app
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:26:07Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.9
    podIPs:
    - ip: 10.42.0.9
    qosClass: BestEffort
    startTime: "2024-03-14T18:25:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
      checksum/sc-dashboard-provider-config: 593c0a8778b83f11fe80ccb21dfb20bc46705e2be3178df1dc4c89d164c8cd9c
      checksum/secret: 8b545cecab0d99e5f2ab94bfc325a3eacb29fa4beef8efbd1cd30323af86de97
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2024-03-14T18:42:44Z"
    generateName: grafana-578dbb87b6-
    labels:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/name: grafana
      pod-template-hash: 578dbb87b6
    name: grafana-578dbb87b6-jf8dh
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: grafana-578dbb87b6
      uid: 64199867-88d9-4fc8-a76c-a8378604009e
    resourceVersion: "1270"
    uid: 9f79ca92-337e-4d5d-b0c0-33ae20287b66
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:10.4.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nv6rd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: grafana
    serviceAccountName: grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: grafana
      name: config
    - emptyDir: {}
      name: storage
    - name: kube-api-access-nv6rd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:42:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:43:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:43:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T18:42:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://eb176fb1c9dbf942f80c93112ac220632b8002c3f401b44a27f2c1c76485ff7a
      image: docker.io/grafana/grafana:10.4.0
      imageID: docker.io/grafana/grafana@sha256:f9811e4e687ffecf1a43adb9b64096c50bc0d7a782f8608530f478b6542de7d5
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T18:43:07Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.10
    podIPs:
    - ip: 10.42.0.10
    qosClass: BestEffort
    startTime: "2024-03-14T18:42:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T21:26:13Z"
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "6585976678"
      pod-template-generation: "1"
    name: node-exporter-7jxss
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 00b87b90-2ff1-4e39-bcd6-76616f14535f
    resourceVersion: "4324"
    uid: 5e312969-aedc-4c47-852a-cb5f74f7867f
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k3d-demo-server-0
    containers:
    - image: prom/node-exporter:latest
      imagePullPolicy: Always
      name: node-exporter
      ports:
      - containerPort: 9100
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-578x7
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: kube-api-access-578x7
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:26:13Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:26:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:26:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:26:13Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://104da73ebbe7cc05d12c801e6b857ca424e0fc2305080a6aa9b68f5cbbeab2a5
      image: docker.io/prom/node-exporter:latest
      imageID: docker.io/prom/node-exporter@sha256:4cb2b9019f1757be8482419002cb7afe028fdba35d47958829e4cfeaf6246d80
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T21:26:21Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.11
    podIPs:
    - ip: 10.42.0.11
    qosClass: BestEffort
    startTime: "2024-03-14T21:26:13Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T21:28:06Z"
    generateName: kube-state-metrics-7dd6f55c7d-
    labels:
      app: kube-state-metrics
      pod-template-hash: 7dd6f55c7d
    name: kube-state-metrics-7dd6f55c7d-dsbqh
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-state-metrics-7dd6f55c7d
      uid: a08eecc0-4fc0-42b6-b555-c335c4fe43e4
    resourceVersion: "4418"
    uid: e1c8be26-422e-47c8-a8d4-dfdc092119d0
  spec:
    containers:
    - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.2.0
      imagePullPolicy: IfNotPresent
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kc98n
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-kc98n
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:28:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:28:11Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:28:11Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:28:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://622d863130481311e260573575f364340b6fee078ee4b7f8b4e1751363707e0a
      image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.2.0
      imageID: k8s.gcr.io/kube-state-metrics/kube-state-metrics@sha256:0ccff0db0a342d264c8f4fe5a0841d727fbb8e6cc0c7e741441771f165262182
      lastState: {}
      name: kube-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T21:28:11Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.13
    podIPs:
    - ip: 10.42.0.13
    qosClass: BestEffort
    startTime: "2024-03-14T21:28:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-14T21:50:38Z"
    generateName: prometheus-deployment-9fd79646c-
    labels:
      app: prometheus
      pod-template-hash: 9fd79646c
    name: prometheus-deployment-9fd79646c-j8m7b
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-deployment-9fd79646c
      uid: acc3615c-8245-4e9b-920a-f68323d54978
    resourceVersion: "4859"
    uid: 93917af1-2b4f-4cea-af5a-eab005946509
  spec:
    containers:
    - image: prom/prometheus
      imagePullPolicy: Always
      name: prometheus
      ports:
      - containerPort: 9090
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zxb47
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k3d-demo-server-0
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-zxb47
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:50:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:50:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:50:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-14T21:50:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5e9b64097a3dc7a1df4bb5330bd34a40b24dd6e5c2935a5d3fac03f6cba1bf1e
      image: docker.io/prom/prometheus:latest
      imageID: docker.io/prom/prometheus@sha256:bc1794e85c9e00293351b967efa267ce6af1c824ac875a9d0c7ac84700a8b53e
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-03-14T21:50:55Z"
    hostIP: 172.18.0.3
    phase: Running
    podIP: 10.42.0.14
    podIPs:
    - ip: 10.42.0.14
    qosClass: BestEffort
    startTime: "2024-03-14T21:50:38Z"
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-03-14T18:10:08Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "192"
    uid: 617dd76f-1acc-4133-bbdf-9be37b6e6f77
  spec:
    clusterIP: 10.43.0.1
    clusterIPs:
    - 10.43.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/4yRwY7TMBCGXwXN2Qlx026zljig3QtCQistcEEcHGdKTRKP5ZkWoSrvjtxmRWEV2Fui+fzpn39OYKP/jIk9BTBw1KCg96EDA4+Yjt4hKBhRbGfFgjmBDYHEiqfA+Zfa7+iEUcrkqXRWZMDS02ufDaAW5/QjYCq+HXsw0Nd8NTlq9eq9D92bt11H4b+KYEcEA44SdoFfhHO0Lr/pDy0W/JMFR1AQE40oezxwpiMlAQO3elM/m7FLNmaBpAPCpGCwLQ7nOvqGCxvjk/ySKH+mgILn1244sGAqeK531vyNzXvdUcL7D4//2GtveQ8GWoerpl7dNo3W23Vtq7q5se1GV7vV7maLu+16ta7cZpvzzu6riEu1TAo4osurzbnfPYABXZXruqxKXeVyKAmD+XJ68l6UlwY39bk9IUcDGPh0/wCTuiYLcXGJ/nj3Bz2iJO9+u/NxnvNfFTAO6ITSwkWmafoVAAD//yO4Hor3AgAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-03-14T18:10:11Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
      objectset.rio.cattle.io/hash: bce283298811743a0386ab510f2f67ef74240c57
    name: kube-dns
    namespace: kube-system
    resourceVersion: "264"
    uid: b7a9cf56-8942-418c-8624-61d79083e72f
  spec:
    clusterIP: 10.43.0.10
    clusterIPs:
    - 10.43.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/4SQQWvjMBCF/8oyZzkbx06cFexh2WMpBFp6KT2M5Umi2pGEZuJSgv97kZNCQpvmJKQ37833dAAM9okiW+9AQ5+Dgta6BjQ8UOytIVCwI8EGBUEfAJ3zgmK943T19SsZYZJJtH5iUKSjifW/bUoAdVX3b45itulb0NAWfKb0ufp1Z13z91/TeHczwuGOQCfEaA1nTLGnOB5H9ttuDmhSRLuvKeN3FtrBoKDDmrqxYxKiIyFORtPtWc5WaJC4T5sux05c9xdcP/BskbegAedNUZvFNDfLKqd8VqyxmNWzaj0v/9QLwqqa1mZdYiL8tjoc36+U4kAmVQo+CoN+PnyGbEUCgxoF0GVZKAjRize+Aw2P/1egQDBuSFbjxMkwvChg6siIj+NXLTnDEL5SDcPwEQAA//8Uey7TawIAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-service
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:12Z"
    labels:
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Metrics-server
      objectset.rio.cattle.io/hash: a5d3bc601c871e123fa32b27f549b6ea770bcf4a
    name: metrics-server
    namespace: kube-system
    resourceVersion: "314"
    uid: f44c55a1-61b7-4fb0-b5fa-cf3a731b0d41
  spec:
    clusterIP: 10.43.215.230
    clusterIPs:
    - 10.43.215.230
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      k8s-app: metrics-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2024-03-14T18:11:05Z"
    finalizers:
    - service.kubernetes.io/load-balancer-cleanup
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-21.2.1_up21.2.0
    name: traefik
    namespace: kube-system
    resourceVersion: "622"
    uid: 11809822-bcd3-45d4-9b85-2cddd986da47
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.146.215
    clusterIPs:
    - 10.43.146.215
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: PreferDualStack
    ports:
    - name: web
      nodePort: 31810
      port: 80
      protocol: TCP
      targetPort: web
    - name: websecure
      nodePort: 30387
      port: 443
      protocol: TCP
      targetPort: websecure
    selector:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/name: traefik
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 172.18.0.3
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: grafana
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-03-14T18:42:44Z"
    labels:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 10.4.0
      helm.sh/chart: grafana-7.3.7
    name: grafana
    namespace: default
    resourceVersion: "1230"
    uid: d4344664-f6b3-4af1-b849-dae5dde25bd4
  spec:
    clusterIP: 10.43.199.78
    clusterIPs:
    - 10.43.199.78
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: service
      port: 80
      protocol: TCP
      targetPort: 3000
    selector:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/name: grafana
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"prometheus-service","namespace":"default"},"spec":{"ports":[{"port":9090,"protocol":"TCP","targetPort":9090}],"selector":{"app":"prometheus"}}}
    creationTimestamp: "2024-03-14T21:51:03Z"
    name: prometheus-service
    namespace: default
    resourceVersion: "4866"
    uid: 01cf7c87-c2ac-482c-97cc-a58c3d06dbe8
  spec:
    clusterIP: 10.43.45.57
    clusterIPs:
    - 10.43.45.57
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/8RVwW7jNhD9lWLOsizbSuoI6CFIgiJo1zFsby8LIxhRo5g1RRLkSBsj0L8XlJ2s0rWToEB34YNBzptH8r3RzBOglX+R89JoyACt9cNmBBFspS4gg2ukyuglMURQEWOBjJA9AWptGFka7cPS5H+TYE8cO2ligcyKYmmGMnBAdDJuvmpyg4dmCxkMm1H0yx9SF78tyTVS0Lt5GiuCDNghlXL7Ibi3KELOts5p4HeeqYI2AuGoe8xKVuQZKwuZrpWKQGFO6s0nbtBvIIPp5LwUuaBkPC7OCqSzfHJ+fpGWNCIsJ9MLcTHB8tdCQAS+EcJodkYpcvF24nts2hTkSZFg4yCDEpWnd1J8I74T4gP4E0ocqHwjVD44EA5Go2lyMR2PYR8/keotiaDUt/s/QYUsNn++iIjWniZv2wiYKquQqcvt1dsHDHqT+8dJ2BMCazaVqTUfCvpSiLBamS1pyDpvIwiHoNTkPGRfnoB00/0f7rNcXN3P7xYriKBBVYetaQJt9AqwuJz9frPsQZK4+w1fIa9vlqv7+eJudddDrq7m32PeOq9D3M77p42SOJ3Eo/Q8Ho/OoF1HICt8CBGHWmzIDbdKWktuoPKsSeI0TuGAmddKzY2SYgcZ3JYzw3NHnjTDSyUGN4UdTBOIwBrHe5leVJsbx5BNkwg2xvO31bFsZ9gIo56fvY7AkTe1ExQKKBhHonaSd1dGMz1yV3hoMZdKsqR9lRUFZF9gdrO6v7z+dDuDddsGed73LU0nP9a4fx34s5wL13jDujSd9L3rlkcJ/jf31kdT/c4LVr5vqiaOpW3SWNr70riv6Iq+mNCuu1v0v/VZr51CBGwUueexGb72siTBkMHMLMWGilqFbr+lIGoYBQNnFMWhvzhNTD40nwo9kwvTzgaubk7cPErPvnP7v1AeGt3AKtR0knnPceUkS4HqsiiM9nda7Y4nrEMnrG2BTEt2yPSwC7KGfir1w+cusJ8Qj581NigV5oogG4UpsLNBtcUrbNdZGbnunBS1c6R5Vlc5ueeHFpAlERTkpaPiWEh3e5+k90e2F4TFDrKkbf8JAAD//yD7SvkWCQAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: /v1, Kind=Service
      objectset.rio.cattle.io/owner-name: traefik
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:11:05Z"
    generation: 1
    labels:
      objectset.rio.cattle.io/hash: 836fcbce022d5dae5b36694fe1eaf389c93af7dc
      svccontroller.k3s.cattle.io/nodeselector: "false"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-11809822
    namespace: kube-system
    resourceVersion: "621"
    uid: 10256f8f-936e-44c1-84e7-4322f354ef90
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: svclb-traefik-11809822
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: svclb-traefik-11809822
          svccontroller.k3s.cattle.io/svcname: traefik
          svccontroller.k3s.cattle.io/svcnamespace: kube-system
      spec:
        automountServiceAccountToken: false
        containers:
        - env:
          - name: SRC_PORT
            value: "80"
          - name: SRC_RANGES
            value: 0.0.0.0/0
          - name: DEST_PROTO
            value: TCP
          - name: DEST_PORT
            value: "80"
          - name: DEST_IPS
            value: 10.43.146.215
          image: rancher/klipper-lb:v0.4.4
          imagePullPolicy: IfNotPresent
          name: lb-tcp-80
          ports:
          - containerPort: 80
            hostPort: 80
            name: lb-tcp-80
            protocol: TCP
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - env:
          - name: SRC_PORT
            value: "443"
          - name: SRC_RANGES
            value: 0.0.0.0/0
          - name: DEST_PROTO
            value: TCP
          - name: DEST_PORT
            value: "443"
          - name: DEST_IPS
            value: 10.43.146.215
          image: rancher/klipper-lb:v0.4.4
          imagePullPolicy: IfNotPresent
          name: lb-tcp-443
          ports:
          - containerPort: 443
            hostPort: 443
            name: lb-tcp-443
            protocol: TCP
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          sysctls:
          - name: net.ipv4.ip_forward
            value: "1"
        serviceAccount: svclb
        serviceAccountName: svclb
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - key: CriticalAddonsOnly
          operator: Exists
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"name":"node-exporter","namespace":"default"},"spec":{"selector":{"matchLabels":{"app":"node-exporter"}},"template":{"metadata":{"labels":{"app":"node-exporter"}},"spec":{"containers":[{"image":"prom/node-exporter:latest","name":"node-exporter","ports":[{"containerPort":9100}]}]}}}}
    creationTimestamp: "2024-03-14T21:26:13Z"
    generation: 1
    name: node-exporter
    namespace: default
    resourceVersion: "4325"
    uid: 00b87b90-2ff1-4e39-bcd6-76616f14535f
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: node-exporter
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: node-exporter
      spec:
        containers:
        - image: prom/node-exporter:latest
          imagePullPolicy: Always
          name: node-exporter
          ports:
          - containerPort: 9100
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xVQW/bOBP9Kx/mLMVW0jaugO/QtbPboq3XqJNeCqOgqZHFNcXhkiMnRqD/vhjJduw2TdrFniyTb4ZvHucN70F58xlDNOQgB+V9HGwySGBtXAE5TNBb2tboGBKokVWhWEF+D8o5YsWGXJS/tPwLNUfks2DoTCtmi2eGBkaSQPLDfbp1GNLVZg05rC/i0c4mS/733rji/2+KgtyzKZyqEXLQFLBw8afg0SstMetmiWncRsYa2gSsWqLtilqPYqq830P6vPIZHDJGybY7dkwBJ9P5E8dWKlaQw1Lj+eji/PVolGWXLy7U8GL0Si1fZsPyvHx1ieXli/MXQ/3yUoh8V9ITpKNHLZQDbozc5VsTmcL2g6kNQz5MIKJFzRQEVCvW1YenymwlJQfFuNp2acla41Y3vlCMfYq7G6c2yli1tAh51ibAWy/MPp1gZR1rb/dxRy30pNDtUVGaHCvjMETIv9yDCiv5gFSTKyGBAbIe7FQayE2UxiIsEjC1WgmjoJyuMAxqE4LA0h14/5tnZ9nwTLq+i5g11s7IGr2FHN6VU+JZwNhbwJoNOoxxFmjZFVQqY5uA11XAWJEtIL9IoGL2fyDLvlcs9z6oUFmuIAFPgSEfDUdyKbrC7o7fXl/PRCrjDBtlJ2jVdo6aXBEhfzVMwGMwVByWMglutMYYj07OEmBTIzX8AHysj4RCL+VB2VnH6uXFAb1DBmLSZCGHm4kwfCYkZe1Pw67Hj4a9zo4Ca+RgdHwkcJFAQFWYfyW5RG4fFM9G2c8q/r3g57+gd8BITdDYtbYVB8a+9WsK0lLZ5fCjgQ74d4Ox39W+ka3hsO4G7Q7aI8UKqJtgeDsmx3jXlamspdtZMBtjcYVXUSvbzWPIS2UjJqCVV0tjDZueiioKsc306vrrb++mk6/zq0+f342vxClFIC97ylpYtL3ofzq7/UTEvxuLu0GTc2iwTWBDtqnxIzVu10e1fM52uh/ZEY66z5VmlfaR8HDCPuePcwx0E5nqo1Td//SZjAtpnsLFg5MnWKrGiokdFTg/moenI50i5GCNa+7kjnww1AlvVYzTnkCvRqptExlDqoNho5UFuaawMRrfaC3FTL81HpPFsH80v9zDGoXYeBffPXSxKyEB8oIUfnB1Z6RJRCMsS9QMOUxprissGiuV92mkqjSQxbPTesR5gWzqrXL4n2auldT/eMqFVOvJ0mo793I1Y3Lyoph9y3TTf/7Lr1Kt7uZrvO3NtzvgfcfylFtFkbt+SeC2QnfjomITS9M/VzChKfGhUGHb99FhLJZm9VF5IWIY65Pr2r8wyX7SHFZEyB40pQLfkihxQD0syXHfDOX2B0bZjc4HNqdx6cEb5KWtlD149CmztIu2bdt/AgAA//+BDg8J/AkAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:11Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      kubernetes.io/name: CoreDNS
      objectset.rio.cattle.io/hash: bce283298811743a0386ab510f2f67ef74240c57
    name: coredns
    namespace: kube-system
    resourceVersion: "490"
    uid: fe85e862-33a0-49fb-8911-aa572fd8cdf7
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: rancher/mirrored-coredns-coredns:1.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
          - mountPath: /etc/coredns/custom
            name: custom-config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
            name: coredns
          name: config-volume
        - configMap:
            defaultMode: 420
            name: coredns-custom
            optional: true
          name: custom-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:10:23Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:10:48Z"
      message: ReplicaSet "coredns-77ccd57875" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xU3W7yRhB9lWqubQMfBCFLvUBJqlZNCEqU3kSoGtZj2LDeXe0Obizkd68Gm/yoIWmlXnl/Zs6emXPGB0Cv/6AQtbOQA3ofB/UIEthpW0AOV+SNayqyDAlUxFggI+QHQGsdI2tno2zd+pkUR+IsaJcpZDaUaTfQAgLJ2Xv3l6WQbuod5LAbx3c39Sj56Xdti5/nReHstxAWK4IcjFNo0sgu4Ib+VVL0qCRzt19TGpvIVEGbgME1mS9L22LcQg6j2bgcX6jpRVmu1Xg4nUyH43IyLkcXs2ExU9MZ/ihwXUwE9ANJj7xNfXC1luZTgO7+DJ/oSQmbQF38r1qKbG50pRnyYQKRDCl2QYIqZLW9ea0AvT//aivgHJBp0xwfcMZou3n0BTJ1YC+PFmvUBteGIB+1CXDjheP9h1g5p8qbU947t5j/wKUvVDnLqC2FCPmTbKsKxZJP59sXGYP4NE2Vs6XeQAIDYjXodv0ne47OwioBsvURuRdleXf152J+e/2wnF9eQwI1mj39ElwlZEpNprin8nW9RBbxTzVmb8q1bbtKQFfivxwCWrWlMPicc14Ps2H2YwJ9wnJvzNIZrRrI4bdy4XgZKHbD9513amf2Fd26veWuY5Use57v2/CG1R2kXSa0KyHug3ZBc3NpMMZFF9e5MLWuoFQFzVqhkXZTqLWiuVLy0uIrfmkfm2IXDAmwMxROP5CnA+xIir7s4Y9DH++saWSIvUSKteH6RUeO0CYHoLIkxZDDwj2oLRV7IwPfwRypBmcokzEKlpiizKyYKjiTeoOW/lfkCiMfdfgEcnVS52RlafstenHTP2Xtvduel6lt278DAAD//8i6p1C4BQAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: local-storage
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:11Z"
    generation: 1
    labels:
      objectset.rio.cattle.io/hash: 183f35c65ffbc3064603f43f1580d8c68a2dabd4
    name: local-path-provisioner
    namespace: kube-system
    resourceVersion: "491"
    uid: 4ff591c2-85a7-46f1-ac9d-7d36efbda96c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        app: local-path-provisioner
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
      spec:
        containers:
        - command:
          - local-path-provisioner
          - start
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/local-path-provisioner:v0.0.24
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:10:23Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:10:48Z"
      message: ReplicaSet "local-path-provisioner-957fdf8bc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xV3W4bNxN9lQ9zvWvv6sdOFtCFIOuLgjqOECktisAQKO5IYsUlWc6sYtXQuxezaztKHcVp0BthRR4enjkznLkHFcyvGMl4BwWoEOh8l0MCW+NKKOAKg/X7Ch1DAhWyKhUrKO5BOedZsfGO5K9f/oGaCfksGn+mFbPFM+PPjZBAcnLff3YY0/VuCwVsu3S0s8uT//1iXDkYlqV3L1I4VSEUIjEaTSlh3GFMy2P5LxNQUFpYtvUSU9oTYwWHBKxaom3C3L6iVIXw7KLvsG8UbaAAzDPs9PqYd7F3oS47ff26LMuyt3qNy0739SrvXV5e9lal3PfNWKBdPyGRAmoRGHFnJJcTQ+zj/tpUhqHIEiC0qNlHAVWK9eb65aAOQsxRMa73Dbm31rj1x1Aqxpbo7qNTO2WsWlqEIj8kwPsg+j58hZV1rIJ9PHdUSD9g7klLjgLX3rEyDiNB8ekeVFzLB6SpxshpaeLgnKsACaQpoa4jpsFHHuRZp581q2KoRU5DxBXGiGWqyjIiUSoR0eCtY4xO2bfTZHz39DnxxI22Y4qaMHW+xJRYcU3NTQ2glZ9GJG9reTuDvE/NDltKtQkbjCnVhpEG8+vZYjy6mozldzZc/PZ2PlkMx7NFp3+xeDN6t5hNht1XveQL7sMPof7BlndePeI6/YtTbCdRR2yjyXA0GXayxfT99e95N+t/i+wZCG4TMJVaS3ajcnqD8bwyMXrJwNfpLnbZ2cVZFxKwZocOiabRL5uCWilj64jzTUTaeFtC0U1gwxzeIMt+UCyP8FwO/gUJNBkpGoT4T3qDTX1N5vPpTMrKOMNG2Su0aj9D7V1JUFxkCQSMxpdPS7k8rVprJDq6PE+ATYW+5i/A77xrUdOW7VMVTxuBTXU+nXtUG6Jnr72FAuajKRxuE4ioSvNTjsjJ/c9b8tyRzr8wRB5CHTVS27r+rJG4+dahhgLyLKuasVP5uIcCLrN3pm1K8oIN70feMd418Shr/edpNDtjcY1j0so20wmKlbKErUXvnd1/8J7/byw+9M6CYy27tRvSjXey+9XaR8IoiciyQwI7b+sK3/naPeSrks/pg5Vtf3lIFldBug4cbiU/IRrfCLaK6KZFtALaRqGjYaOVFeMx7ozGodbCfXOiZNhbjI/j99M9bFEMGj3QNCOTJFoZTEGQ0vlhfGfE4ENyD7haoZaE3/iZ3mBZW+lhLU0jKXqLZ9LRokNGklEm1Rm9TYNVDv9T5koRt1P0OeXto+9tpFgF3l8ZGWSHb7l9OBz+DgAA//+Ky3kD1QgAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-deployment
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:12Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      objectset.rio.cattle.io/hash: e10e245e13e46a725c9dddd4f9eb239f147774fd
    name: metrics-server
    namespace: kube-system
    resourceVersion: "546"
    uid: 59062d7c-5208-4d11-8b13-45c1b4d6c4e0
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
        name: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
          image: rancher/mirrored-metrics-server:v0.6.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:10:23Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:10:23Z"
      lastUpdateTime: "2024-03-14T18:11:01Z"
      message: ReplicaSet "metrics-server-648b5df564" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2024-03-14T18:11:05Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-21.2.1_up21.2.0
    name: traefik
    namespace: kube-system
    resourceVersion: "637"
    uid: f07771a5-698c-4c44-8633-4f10bf34579b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: traefik-kube-system
        app.kubernetes.io/name: traefik
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9100"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: traefik-kube-system
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: traefik
          helm.sh/chart: traefik-21.2.1_up21.2.0
      spec:
        containers:
        - args:
          - --global.checknewversion
          - --global.sendanonymoususage
          - --entrypoints.metrics.address=:9100/tcp
          - --entrypoints.traefik.address=:9000/tcp
          - --entrypoints.web.address=:8000/tcp
          - --entrypoints.websecure.address=:8443/tcp
          - --api.dashboard=true
          - --ping=true
          - --metrics.prometheus=true
          - --metrics.prometheus.entrypoint=metrics
          - --providers.kubernetescrd
          - --providers.kubernetesingress
          - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
          - --entrypoints.websecure.http.tls=true
          image: rancher/mirrored-library-traefik:2.9.10
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: traefik
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          - containerPort: 9000
            name: traefik
            protocol: TCP
          - containerPort: 8000
            name: web
            protocol: TCP
          - containerPort: 8443
            name: websecure
            protocol: TCP
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 65532
            runAsNonRoot: true
            runAsUser: 65532
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: data
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65532
        serviceAccount: traefik
        serviceAccountName: traefik
        terminationGracePeriodSeconds: 60
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: data
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:11:20Z"
      lastUpdateTime: "2024-03-14T18:11:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:11:05Z"
      lastUpdateTime: "2024-03-14T18:11:20Z"
      message: ReplicaSet "traefik-64f55bb67d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-14T18:25:37Z"
    generation: 1
    labels:
      app: demo
    name: demo
    namespace: default
    resourceVersion: "922"
    uid: 82bd7144-eeaf-4919-81a7-331136095cd3
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: demo
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: demo
      spec:
        containers:
        - image: andriy1fanatic/app:v1.0.0
          imagePullPolicy: IfNotPresent
          name: app
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:26:07Z"
      lastUpdateTime: "2024-03-14T18:26:07Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:25:37Z"
      lastUpdateTime: "2024-03-14T18:26:07Z"
      message: ReplicaSet "demo-794b7cb558" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: grafana
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-03-14T18:42:44Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 10.4.0
      helm.sh/chart: grafana-7.3.7
    name: grafana
    namespace: default
    resourceVersion: "1274"
    uid: ff00d899-b527-4e56-84b9-8f7cc0959386
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: grafana
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: 593c0a8778b83f11fe80ccb21dfb20bc46705e2be3178df1dc4c89d164c8cd9c
          checksum/secret: 8b545cecab0d99e5f2ab94bfc325a3eacb29fa4beef8efbd1cd30323af86de97
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: grafana
          app.kubernetes.io/name: grafana
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:10.4.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: grafana
        serviceAccountName: grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: grafana
          name: config
        - emptyDir: {}
          name: storage
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T18:43:24Z"
      lastUpdateTime: "2024-03-14T18:43:24Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T18:42:44Z"
      lastUpdateTime: "2024-03-14T18:43:24Z"
      message: ReplicaSet "grafana-578dbb87b6" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"kube-state-metrics","namespace":"default"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"kube-state-metrics"}},"template":{"metadata":{"labels":{"app":"kube-state-metrics"}},"spec":{"containers":[{"image":"k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.2.0","name":"kube-state-metrics","ports":[{"containerPort":8080}]}]}}}}
    creationTimestamp: "2024-03-14T21:26:29Z"
    generation: 2
    name: kube-state-metrics
    namespace: default
    resourceVersion: "4429"
    uid: 3a68f33e-91e4-4b86-96cf-f96ad2c41e78
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-state-metrics
      spec:
        containers:
        - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.2.0
          imagePullPolicy: IfNotPresent
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T21:28:11Z"
      lastUpdateTime: "2024-03-14T21:28:11Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T21:26:29Z"
      lastUpdateTime: "2024-03-14T21:28:11Z"
      message: ReplicaSet "kube-state-metrics-7dd6f55c7d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"prometheus-deployment","namespace":"default"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"prometheus"}},"template":{"metadata":{"labels":{"app":"prometheus"}},"spec":{"containers":[{"image":"prom/prometheus","name":"prometheus","ports":[{"containerPort":9090}]}]}}}}
    creationTimestamp: "2024-03-14T21:50:38Z"
    generation: 1
    name: prometheus-deployment
    namespace: default
    resourceVersion: "4861"
    uid: 9753c21b-f3a0-441b-89b9-d5718d2edd25
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: prometheus
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: prometheus
      spec:
        containers:
        - image: prom/prometheus
          imagePullPolicy: Always
          name: prometheus
          ports:
          - containerPort: 9090
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-03-14T21:50:55Z"
      lastUpdateTime: "2024-03-14T21:50:55Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-03-14T21:50:38Z"
      lastUpdateTime: "2024-03-14T21:50:55Z"
      message: ReplicaSet "prometheus-deployment-9fd79646c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xVQW/bOBP9Kx/mLMVW0jaugO/QtbPboq3XqJNeCqOgqZHFNcXhkiMnRqD/vhjJduw2TdrFniyTb4ZvHucN70F58xlDNOQgB+V9HGwySGBtXAE5TNBb2tboGBKokVWhWEF+D8o5YsWGXJS/tPwLNUfks2DoTCtmi2eGBkaSQPLDfbp1GNLVZg05rC/i0c4mS/733rji/2+KgtyzKZyqEXLQFLBw8afg0SstMetmiWncRsYa2gSsWqLtilqPYqq830P6vPIZHDJGybY7dkwBJ9P5E8dWKlaQw1Lj+eji/PVolGWXLy7U8GL0Si1fZsPyvHx1ieXli/MXQ/3yUoh8V9ITpKNHLZQDbozc5VsTmcL2g6kNQz5MIKJFzRQEVCvW1YenymwlJQfFuNp2acla41Y3vlCMfYq7G6c2yli1tAh51ibAWy/MPp1gZR1rb/dxRy30pNDtUVGaHCvjMETIv9yDCiv5gFSTKyGBAbIe7FQayE2UxiIsEjC1WgmjoJyuMAxqE4LA0h14/5tnZ9nwTLq+i5g11s7IGr2FHN6VU+JZwNhbwJoNOoxxFmjZFVQqY5uA11XAWJEtIL9IoGL2fyDLvlcs9z6oUFmuIAFPgSEfDUdyKbrC7o7fXl/PRCrjDBtlJ2jVdo6aXBEhfzVMwGMwVByWMglutMYYj07OEmBTIzX8AHysj4RCL+VB2VnH6uXFAb1DBmLSZCGHm4kwfCYkZe1Pw67Hj4a9zo4Ca+RgdHwkcJFAQFWYfyW5RG4fFM9G2c8q/r3g57+gd8BITdDYtbYVB8a+9WsK0lLZ5fCjgQ74d4Ox39W+ka3hsO4G7Q7aI8UKqJtgeDsmx3jXlamspdtZMBtjcYVXUSvbzWPIS2UjJqCVV0tjDZueiioKsc306vrrb++mk6/zq0+f342vxClFIC97ylpYtL3ofzq7/UTEvxuLu0GTc2iwTWBDtqnxIzVu10e1fM52uh/ZEY66z5VmlfaR8HDCPuePcwx0E5nqo1Td//SZjAtpnsLFg5MnWKrGiokdFTg/moenI50i5GCNa+7kjnww1AlvVYzTnkCvRqptExlDqoNho5UFuaawMRrfaC3FTL81HpPFsH80v9zDGoXYeBffPXSxKyEB8oIUfnB1Z6RJRCMsS9QMOUxprissGiuV92mkqjSQxbPTesR5gWzqrXL4n2auldT/eMqFVOvJ0mo793I1Y3Lyoph9y3TTf/7Lr1Kt7uZrvO3NtzvgfcfylFtFkbt+SeC2QnfjomITS9M/VzChKfGhUGHb99FhLJZm9VF5IWIY65Pr2r8wyX7SHFZEyB40pQLfkihxQD0syXHfDOX2B0bZjc4HNqdx6cEb5KWtlD149CmztIu2bdt/AgAA//+BDg8J/AkAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:23Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 77ccd57875
    name: coredns-77ccd57875
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: fe85e862-33a0-49fb-8911-aa572fd8cdf7
    resourceVersion: "487"
    uid: 6005681a-ec0c-4eef-9581-cc177eb0dc06
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 77ccd57875
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 77ccd57875
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: rancher/mirrored-coredns-coredns:1.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
          - mountPath: /etc/coredns/custom
            name: custom-config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
            name: coredns
          name: config-volume
        - configMap:
            defaultMode: 420
            name: coredns-custom
            optional: true
          name: custom-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xU3W7yRhB9lWqubQMfBCFLvUBJqlZNCEqU3kSoGtZj2LDeXe0Obizkd68Gm/yoIWmlXnl/Zs6emXPGB0Cv/6AQtbOQA3ofB/UIEthpW0AOV+SNayqyDAlUxFggI+QHQGsdI2tno2zd+pkUR+IsaJcpZDaUaTfQAgLJ2Xv3l6WQbuod5LAbx3c39Sj56Xdti5/nReHstxAWK4IcjFNo0sgu4Ib+VVL0qCRzt19TGpvIVEGbgME1mS9L22LcQg6j2bgcX6jpRVmu1Xg4nUyH43IyLkcXs2ExU9MZ/ihwXUwE9ANJj7xNfXC1luZTgO7+DJ/oSQmbQF38r1qKbG50pRnyYQKRDCl2QYIqZLW9ea0AvT//aivgHJBp0xwfcMZou3n0BTJ1YC+PFmvUBteGIB+1CXDjheP9h1g5p8qbU947t5j/wKUvVDnLqC2FCPmTbKsKxZJP59sXGYP4NE2Vs6XeQAIDYjXodv0ne47OwioBsvURuRdleXf152J+e/2wnF9eQwI1mj39ElwlZEpNprin8nW9RBbxTzVmb8q1bbtKQFfivxwCWrWlMPicc14Ps2H2YwJ9wnJvzNIZrRrI4bdy4XgZKHbD9513amf2Fd26veWuY5Use57v2/CG1R2kXSa0KyHug3ZBc3NpMMZFF9e5MLWuoFQFzVqhkXZTqLWiuVLy0uIrfmkfm2IXDAmwMxROP5CnA+xIir7s4Y9DH++saWSIvUSKteH6RUeO0CYHoLIkxZDDwj2oLRV7IwPfwRypBmcokzEKlpiizKyYKjiTeoOW/lfkCiMfdfgEcnVS52RlafstenHTP2Xtvduel6lt278DAAD//8i6p1C4BQAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: local-storage
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:23Z"
    generation: 1
    labels:
      app: local-path-provisioner
      pod-template-hash: 957fdf8bc
    name: local-path-provisioner-957fdf8bc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: local-path-provisioner
      uid: 4ff591c2-85a7-46f1-ac9d-7d36efbda96c
    resourceVersion: "489"
    uid: 316f82c2-47a5-4b8b-b49e-2ff80d439ba6
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: local-path-provisioner
        pod-template-hash: 957fdf8bc
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
          pod-template-hash: 957fdf8bc
      spec:
        containers:
        - command:
          - local-path-provisioner
          - start
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/local-path-provisioner:v0.0.24
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xV3W4bNxN9lQ9zvWvv6sdOFtCFIOuLgjqOECktisAQKO5IYsUlWc6sYtXQuxezaztKHcVp0BthRR4enjkznLkHFcyvGMl4BwWoEOh8l0MCW+NKKOAKg/X7Ch1DAhWyKhUrKO5BOedZsfGO5K9f/oGaCfksGn+mFbPFM+PPjZBAcnLff3YY0/VuCwVsu3S0s8uT//1iXDkYlqV3L1I4VSEUIjEaTSlh3GFMy2P5LxNQUFpYtvUSU9oTYwWHBKxaom3C3L6iVIXw7KLvsG8UbaAAzDPs9PqYd7F3oS47ff26LMuyt3qNy0739SrvXV5e9lal3PfNWKBdPyGRAmoRGHFnJJcTQ+zj/tpUhqHIEiC0qNlHAVWK9eb65aAOQsxRMa73Dbm31rj1x1Aqxpbo7qNTO2WsWlqEIj8kwPsg+j58hZV1rIJ9PHdUSD9g7klLjgLX3rEyDiNB8ekeVFzLB6SpxshpaeLgnKsACaQpoa4jpsFHHuRZp581q2KoRU5DxBXGiGWqyjIiUSoR0eCtY4xO2bfTZHz39DnxxI22Y4qaMHW+xJRYcU3NTQ2glZ9GJG9reTuDvE/NDltKtQkbjCnVhpEG8+vZYjy6mozldzZc/PZ2PlkMx7NFp3+xeDN6t5hNht1XveQL7sMPof7BlndePeI6/YtTbCdRR2yjyXA0GXayxfT99e95N+t/i+wZCG4TMJVaS3ajcnqD8bwyMXrJwNfpLnbZ2cVZFxKwZocOiabRL5uCWilj64jzTUTaeFtC0U1gwxzeIMt+UCyP8FwO/gUJNBkpGoT4T3qDTX1N5vPpTMrKOMNG2Su0aj9D7V1JUFxkCQSMxpdPS7k8rVprJDq6PE+ATYW+5i/A77xrUdOW7VMVTxuBTXU+nXtUG6Jnr72FAuajKRxuE4ioSvNTjsjJ/c9b8tyRzr8wRB5CHTVS27r+rJG4+dahhgLyLKuasVP5uIcCLrN3pm1K8oIN70feMd418Shr/edpNDtjcY1j0so20wmKlbKErUXvnd1/8J7/byw+9M6CYy27tRvSjXey+9XaR8IoiciyQwI7b+sK3/naPeSrks/pg5Vtf3lIFldBug4cbiU/IRrfCLaK6KZFtALaRqGjYaOVFeMx7ozGodbCfXOiZNhbjI/j99M9bFEMGj3QNCOTJFoZTEGQ0vlhfGfE4ENyD7haoZaE3/iZ3mBZW+lhLU0jKXqLZ9LRokNGklEm1Rm9TYNVDv9T5koRt1P0OeXto+9tpFgF3l8ZGWSHb7l9OBz+DgAA//+Ky3kD1QgAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-deployment
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:23Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      pod-template-hash: 648b5df564
    name: metrics-server-648b5df564
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server
      uid: 59062d7c-5208-4d11-8b13-45c1b4d6c4e0
    resourceVersion: "545"
    uid: fed973cf-7d15-480e-9c16-86c686e3b73b
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 648b5df564
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 648b5df564
        name: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
          image: rancher/mirrored-metrics-server:v0.6.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2024-03-14T18:11:05Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-21.2.1_up21.2.0
      pod-template-hash: 64f55bb67d
    name: traefik-64f55bb67d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: traefik
      uid: f07771a5-698c-4c44-8633-4f10bf34579b
    resourceVersion: "636"
    uid: 3df2d24f-7ad6-4e00-9ac6-4f21e217cb57
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: traefik-kube-system
        app.kubernetes.io/name: traefik
        pod-template-hash: 64f55bb67d
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9100"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: traefik-kube-system
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: traefik
          helm.sh/chart: traefik-21.2.1_up21.2.0
          pod-template-hash: 64f55bb67d
      spec:
        containers:
        - args:
          - --global.checknewversion
          - --global.sendanonymoususage
          - --entrypoints.metrics.address=:9100/tcp
          - --entrypoints.traefik.address=:9000/tcp
          - --entrypoints.web.address=:8000/tcp
          - --entrypoints.websecure.address=:8443/tcp
          - --api.dashboard=true
          - --ping=true
          - --metrics.prometheus=true
          - --metrics.prometheus.entrypoint=metrics
          - --providers.kubernetescrd
          - --providers.kubernetesingress
          - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
          - --entrypoints.websecure.http.tls=true
          image: rancher/mirrored-library-traefik:2.9.10
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: traefik
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          - containerPort: 9000
            name: traefik
            protocol: TCP
          - containerPort: 8000
            name: web
            protocol: TCP
          - containerPort: 8443
            name: websecure
            protocol: TCP
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 65532
            runAsNonRoot: true
            runAsUser: 65532
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: data
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65532
        serviceAccount: traefik
        serviceAccountName: traefik
        terminationGracePeriodSeconds: 60
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: data
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-14T18:25:37Z"
    generation: 1
    labels:
      app: demo
      pod-template-hash: 794b7cb558
    name: demo-794b7cb558
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: demo
      uid: 82bd7144-eeaf-4919-81a7-331136095cd3
    resourceVersion: "921"
    uid: 649259dd-b46d-43b8-8e66-9dcb31b2ffd8
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: demo
        pod-template-hash: 794b7cb558
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: demo
          pod-template-hash: 794b7cb558
      spec:
        containers:
        - image: andriy1fanatic/app:v1.0.0
          imagePullPolicy: IfNotPresent
          name: app
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: grafana
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-03-14T18:42:44Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/name: grafana
      pod-template-hash: 578dbb87b6
    name: grafana-578dbb87b6
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: grafana
      uid: ff00d899-b527-4e56-84b9-8f7cc0959386
    resourceVersion: "1273"
    uid: 64199867-88d9-4fc8-a76c-a8378604009e
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: grafana
        app.kubernetes.io/name: grafana
        pod-template-hash: 578dbb87b6
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: 593c0a8778b83f11fe80ccb21dfb20bc46705e2be3178df1dc4c89d164c8cd9c
          checksum/secret: 8b545cecab0d99e5f2ab94bfc325a3eacb29fa4beef8efbd1cd30323af86de97
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: grafana
          app.kubernetes.io/name: grafana
          pod-template-hash: 578dbb87b6
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:10.4.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: grafana
        serviceAccountName: grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: grafana
          name: config
        - emptyDir: {}
          name: storage
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-03-14T21:28:06Z"
    generation: 1
    labels:
      app: kube-state-metrics
      pod-template-hash: 7dd6f55c7d
    name: kube-state-metrics-7dd6f55c7d
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-state-metrics
      uid: 3a68f33e-91e4-4b86-96cf-f96ad2c41e78
    resourceVersion: "4419"
    uid: a08eecc0-4fc0-42b6-b555-c335c4fe43e4
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: kube-state-metrics
        pod-template-hash: 7dd6f55c7d
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-state-metrics
          pod-template-hash: 7dd6f55c7d
      spec:
        containers:
        - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.2.0
          imagePullPolicy: IfNotPresent
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-14T21:26:29Z"
    generation: 2
    labels:
      app: kube-state-metrics
      pod-template-hash: 7d87bc7d8
    name: kube-state-metrics-7d87bc7d8
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-state-metrics
      uid: 3a68f33e-91e4-4b86-96cf-f96ad2c41e78
    resourceVersion: "4428"
    uid: 566c7368-55ea-41f2-92b6-f82afd218642
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: kube-state-metrics
        pod-template-hash: 7d87bc7d8
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-state-metrics
          pod-template-hash: 7d87bc7d8
      spec:
        containers:
        - image: quay.io/coreos/kube-state-metrics:v2.2.0
          imagePullPolicy: IfNotPresent
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-14T21:50:38Z"
    generation: 1
    labels:
      app: prometheus
      pod-template-hash: 9fd79646c
    name: prometheus-deployment-9fd79646c
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-deployment
      uid: 9753c21b-f3a0-441b-89b9-d5718d2edd25
    resourceVersion: "4860"
    uid: acc3615c-8245-4e9b-920a-f68323d54978
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
        pod-template-hash: 9fd79646c
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: prometheus
          pod-template-hash: 9fd79646c
      spec:
        containers:
        - image: prom/prometheus
          imagePullPolicy: Always
          name: prometheus
          ports:
          - containerPort: 9090
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/job-tracking: ""
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/7RVUY/iNhD+K9VI99QkJCEsm0j3ELhQ6O0CCuyqVbVCxkzAxbEj26E9If575ZC7hu11e324t9ie7/P3jWcmZyAVe0almRSQwJYYeuidAnDgyMQOEvhZbsGBEg3ZEUMgOQMRQhpimBTaLuX2d6RGo/EUkx4lxnD0mOwxiz4gL10qhVGSc1QuPRBlXIV7po1qOMD5Vwb5h0Dl7k/HlqhzdAqcHz4ysXs/RV6OLel/8ghSIiRgFMGCHV2qdt8E0RWhFnest+jqT9pgCRcHqMJG/pqVqA0pK0hEzbkDnGyRN4mxkhu/2nulvtn9Zi0Hog+QQHRfFP3dgPaDYLjtD8OC7igZ+PEwHhRxEQ79kBT+IA6tutZrk30mtCGcu7eXvWFNV0it/i2hR1kUD6xkBpLA930HDJYVJwbt+Rs18YZ1KQq2n14traZpOLh7n/VH/jiKwvh+Mg7GQRSnk9EkGt/H8d1kFIdROEyzKMiiuygexf1onEbxII6D0fC7PMSlkwJbuYQJVBqS385A1N5+QJtSeHEAxak5ajM+Tx8zcOBEeP262C7Ol6jnLF/NFvPuVp4tF931NHt43HzIZ89Z3uHTSBWabtx4mubrjb12tUzH3btvX/UW0Ak7GFPppNd7d/74NMryebbOVpt0Obu862n7ovSaJN3reHHDwAu94Me6CoN/iP6KuXWa/5T9L5Xp03q6Waar1WacZx+y+XqWPqw6sIJwjV3AfLFZ5otffu3EePpEHY/yWhtUHpeUcCfwvSj0fM/vBXfNot8uulyTdPbwlGeb5eJhNu4yKvz88pcXB1hJ9s0uEfSAqnfkrKpQubbGkpPv3Xu+u60Z34V+2PcHgQ8tZllzvpSc0U+QwKyYS7NUqFEYuOlccEChlrWiaMv44sBJ8rrER1kLcy3I0n4uibHN1LbW3xyNat0Yu41rx2UbZmvc3n15saaE3OEKOVIjle0A+z5KoEHdjEUNCXAm6j9t6ynbcMp8sbIQE8J4rRAc0KhOjGJKqb163plHt3Poakl3e6jV7Xyu9uTcfrUs13/INcp91blNyxZs/0gqixNdRGv0FvK1NDQTwBBTN2m//BUAAP//lzVsTiMHAAA
      objectset.rio.cattle.io/id: helm-controller-chart-registration
      objectset.rio.cattle.io/owner-gvk: helm.cattle.io/v1, Kind=HelmChart
      objectset.rio.cattle.io/owner-name: traefik-crd
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:13Z"
    generation: 1
    labels:
      helmcharts.helm.cattle.io/chart: traefik-crd
      objectset.rio.cattle.io/hash: 48ff3d5c3117b372fcdca509795f9f2702af0592
    name: helm-install-traefik-crd
    namespace: kube-system
    resourceVersion: "600"
    uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
  spec:
    backoffLimit: 1000
    completionMode: NonIndexed
    completions: 1
    parallelism: 1
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
    suspend: false
    template:
      metadata:
        annotations:
          helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
          batch.kubernetes.io/job-name: helm-install-traefik-crd
          controller-uid: f51f9789-0222-4ef8-97b2-a1ae7c3c5864
          helmcharts.helm.cattle.io/chart: traefik-crd
          job-name: helm-install-traefik-crd
      spec:
        containers:
        - args:
          - install
          env:
          - name: NAME
            value: traefik-crd
          - name: VERSION
          - name: REPO
          - name: HELM_DRIVER
            value: secret
          - name: CHART_NAMESPACE
            value: kube-system
          - name: CHART
            value: https://%{KUBERNETES_API}%/static/charts/traefik-crd-21.2.1+up21.2.0.tgz
          - name: HELM_VERSION
          - name: TARGET_NAMESPACE
            value: kube-system
          - name: AUTH_PASS_CREDENTIALS
            value: "false"
          - name: NO_PROXY
            value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
          - name: FAILURE_POLICY
            value: reinstall
          image: rancher/klipper-helm:v0.8.0-build20230510
          imagePullPolicy: IfNotPresent
          name: helm
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /config
            name: values
          - mountPath: /chart
            name: content
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: helm-traefik-crd
        serviceAccountName: helm-traefik-crd
        terminationGracePeriodSeconds: 30
        volumes:
        - name: values
          secret:
            defaultMode: 420
            secretName: chart-values-traefik-crd
        - configMap:
            defaultMode: 420
            name: chart-content-traefik-crd
          name: content
  status:
    completionTime: "2024-03-14T18:11:07Z"
    conditions:
    - lastProbeTime: "2024-03-14T18:11:07Z"
      lastTransitionTime: "2024-03-14T18:11:07Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-03-14T18:10:23Z"
    succeeded: 1
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/job-tracking: ""
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xVUY/qNhP9K59Guk9fEgLZbJZI+xAgFHp3IQrsqlW1QsZMwMWxI9uhXSH+e+WQezfb3m5vpb7ZzszxOeM5kzOQij2j0kwKiGFLDD30Tn1w4MjEDmL4UW7BgRIN2RFDID4DEUIaYpgU2m7l9lekRqPxFJMeJcZw9JjsMZt9QF66VAqjJOeoXHogyrgK90wb1WCA87cI8jeByt2fji1Q59Op7/zvMxO7+xnycmxB/xFHkBIhBqMIFuz4XeG6ItTmHOstuvpVGyzh4gBV2FBfsxK1IWUFsag5d4CTLfKmKJZuo1V7f2LenH4XjwPRB4iB+sUwQhKRQYjBDmnUH4YRjUgwuOmT4K4IMCwIhoVl1mpsqs6ENoRz9+2iDyTpCqnlvSX0KIvigZXMQNz3fd8Bg2XFiUH7/YM++ECyFAXbz65yVrNkEN7eh9E4uBsNp6PR7ShIg7EfTu+iYZCO/SAMJ8NhGE6jG3+UhDeTKJ0OJsPbyTCa3k1u//MHuHTk204lTKDSEP9yBqL2dgFtKcEB19VoXG0UE3twYM/llnDvWscJFqTmJr829+s9vDiA4tQgtQ+zSB5TcOBEeN3txYvzNeI5zVfz5aJ7lKfZsrufpQ+Pm0k+f07zDpZGqtB048azJF9v7JWrLBl3733/+O8TOmEHYyod93qfzp+fRmm+SNfpapNk88unnrYPT6+11L1WhzvoewOv//+6ahb+X0h/Q9w6yX9I/xXL5Gk922TJarUZ5+kkXaznycOqk1YQrrGbsFhusnz508+dGE+fqONRXmuDyuOSEu70fe9m4Pme3+vfNpug3XSxpsn84SlPN9nyYT7uIir80iSXFwdYSfbNKRH0gKp35KyqULm2FeOT7915vrutGd8N/EHgh30f2pys5jyTnNFXiGFeLKTJFGoUBt6ZGxxQqGWtKNpuvzhwkrwu8VHWwlx7t7TLjBjrudaBbxgNa90Iex/XTtI2zNrB3n15saKE3OEKOVIjlTWLfR8l0KBupqaGGDgT9e/Wocr6UpmvUpZiShivFYIDGtWJUUwotVcvOiPrbVRd5eiud1rOzpdOj8/tqkW4/lquUW7H3I2rC7Z/JJXNEd3oVuBb+LekNwPCEFM3pb78EQAA///RZzjuMgcAAA
      objectset.rio.cattle.io/id: helm-controller-chart-registration
      objectset.rio.cattle.io/owner-gvk: helm.cattle.io/v1, Kind=HelmChart
      objectset.rio.cattle.io/owner-name: traefik
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-03-14T18:10:13Z"
    generation: 1
    labels:
      helmcharts.helm.cattle.io/chart: traefik
      objectset.rio.cattle.io/hash: c0f97ea7a25e3dec71957c7a3241a38f3e5fae5f
    name: helm-install-traefik
    namespace: kube-system
    resourceVersion: "610"
    uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
  spec:
    backoffLimit: 1000
    completionMode: NonIndexed
    completions: 1
    parallelism: 1
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
    suspend: false
    template:
      metadata:
        annotations:
          helmcharts.helm.cattle.io/configHash: SHA256=57C38B9FBB6B3E3C05F8793EC0355D9955F740BA54D7EF2D96D97F8D678F2B0E
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
          batch.kubernetes.io/job-name: helm-install-traefik
          controller-uid: 43495279-b8b5-4a78-a6f0-2474a3e58ba0
          helmcharts.helm.cattle.io/chart: traefik
          job-name: helm-install-traefik
      spec:
        containers:
        - args:
          - install
          - --set-string
          - global.systemDefaultRegistry=
          env:
          - name: NAME
            value: traefik
          - name: VERSION
          - name: REPO
          - name: HELM_DRIVER
            value: secret
          - name: CHART_NAMESPACE
            value: kube-system
          - name: CHART
            value: https://%{KUBERNETES_API}%/static/charts/traefik-21.2.1+up21.2.0.tgz
          - name: HELM_VERSION
          - name: TARGET_NAMESPACE
            value: kube-system
          - name: AUTH_PASS_CREDENTIALS
            value: "false"
          - name: NO_PROXY
            value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
          - name: FAILURE_POLICY
            value: reinstall
          image: rancher/klipper-helm:v0.8.0-build20230510
          imagePullPolicy: IfNotPresent
          name: helm
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /config
            name: values
          - mountPath: /chart
            name: content
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: helm-traefik
        serviceAccountName: helm-traefik
        terminationGracePeriodSeconds: 30
        volumes:
        - name: values
          secret:
            defaultMode: 420
            secretName: chart-values-traefik
        - configMap:
            defaultMode: 420
            name: chart-content-traefik
          name: content
  status:
    completionTime: "2024-03-14T18:11:08Z"
    conditions:
    - lastProbeTime: "2024-03-14T18:11:08Z"
      lastTransitionTime: "2024-03-14T18:11:08Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-03-14T18:10:23Z"
    succeeded: 1
    uncountedTerminatedPods: {}
kind: List
metadata:
  resourceVersion: ""
